{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests,time,os,csv,re,logging\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url_base='http://sh.lianjia.com/ershoufang/d'\n",
    "date=time.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=os.path.join(os.getcwd(),'results/get_index.log')\n",
    "logging.basicConfig(filename=log_dir,level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    try:\n",
    "        r=requests.get(url,timeout=16)\n",
    "        status=r.status_code\n",
    "        r.raise_for_status()\n",
    "        r.encoding=r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        now_time=time.strftime('%Y%m%d%H%M%S')\n",
    "        logging.info(now_time +'      ' +'get_html 异常, ' '    url：'+ url)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_index_page(date,index_page):\n",
    "    path=os.path.join(os.getcwd(),'results/index_info.csv')\n",
    "    fieldnames=['date','total_num','on_sale_num','saled_in_90d','last_day_viewed',\n",
    "                'key','title','total_price','total_price_unit','per_price','per_price_unit','prop1']\n",
    "    if  not os.path.exists(path):     #如果文件不存在，创建文件并写入表头\n",
    "        csv_file=open(path,'w',newline='')\n",
    "        writer=csv.DictWriter(csv_file,fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        csv_file.close()\n",
    "        \n",
    "    csv_file=open(path,'a+',newline='')\n",
    "    writer=csv.DictWriter(csv_file,fieldnames=fieldnames)\n",
    "    \n",
    "    item={}\n",
    "    \n",
    "    soup=BeautifulSoup(index_page,'html.parser')\n",
    "    \n",
    "    #get_basic_info\n",
    "    total_num=soup.find('div',attrs={'class':'search-result'}).span.string\n",
    "    strong_num=soup.find_all('span',attrs={'class':'num strong-num'})\n",
    "    on_sale_num=strong_num[0].string                #在售总数\n",
    "    saled_in_90d=strong_num[1].string               #近90天成交\n",
    "    last_day_viewed=strong_num[2].string            #昨天带看次数\n",
    "    \n",
    "    \n",
    "    \n",
    "    #update_basic_info\n",
    "    item.update({'date':date,'total_num':total_num,'on_sale_num':on_sale_num,'saled_in_90d':saled_in_90d,\n",
    "                'last_day_viewed':last_day_viewed})\n",
    "    \n",
    "    \n",
    "    index_info=soup.find_all('a',attrs={'class':'text link-hover-green js_triggerGray js_fanglist_title'})\n",
    "    for a in index_info:\n",
    "        key=a['key']\n",
    "        title=a['title']\n",
    "        item.update({'key':key,'title':title})\n",
    "        \n",
    "        price_div=a.parent.next_sibling.next_sibling\n",
    "        total_price=price_div.find('span',attrs={'class':'total-price strong-num'}).string\n",
    "        total_price_unit=price_div.find('span',attrs={'class':'unit'}).string\n",
    "        per_price_info=price_div.find('span',attrs={'class':'info-col price-item minor'}).string\n",
    "        per_price_info=re.search('(\\d+)(\\S{3})',per_price_info).groups()\n",
    "        per_price=per_price_info[0]\n",
    "        per_price_unit=per_price_info[1]\n",
    "        \n",
    "        prop_div=price_div.next_sibling.next_sibling\n",
    "        props=prop_div.find_all('span',attrs={'class':'c-prop-tag2'})\n",
    "        \n",
    "        if len(props)>0:\n",
    "            if \"距离\" in props[0].string:\n",
    "                prop1=props[0].string\n",
    "            else:\n",
    "                prop1=\"\"\n",
    "        else:\n",
    "            prop1=\"\"\n",
    "            \n",
    "#         prop2=props[1].string\n",
    "#         prop3=props[2].string\n",
    "        \n",
    "        item.update({'total_price':total_price,'total_price_unit':total_price_unit,'per_price':per_price,\n",
    "                    'per_price_unit':per_price_unit,'prop1':prop1})\n",
    "        \n",
    "        writer.writerow(item)    #定义writer2csv函数，每次调用函数写入item,结果是重复写入最后一个item，改用writer写入，无问题\n",
    "        \n",
    "        \n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_detail_page(detail_page):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_items():\n",
    "    sleep_time=5\n",
    "    for i in range(1,101):\n",
    "        url=url_base+str(i)\n",
    "        index_page=get_html(url)\n",
    "        if index_page!=None：\n",
    "            parse_index_page(date,total_num,index_page)\n",
    "            time.sleep(sleep_time)\n",
    "            print(i)\n",
    "            sleep_time+=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_agian(error_list):\n",
    "    sleep_time=5\n",
    "    new_error_list=[]\n",
    "    for i in error_list:\n",
    "        url=url_base+str(i)\n",
    "        index_page=get_html(url)\n",
    "        if index_page!=None:\n",
    "            parse_index_page(date,index_page)\n",
    "            time.sleep(sleep_time)\n",
    "            sleep_time+=0.1\n",
    "        else:\n",
    "            new_error_list.append(i)\n",
    "            now_time=time.strftime('%Y%m%d%H%M%S')\n",
    "            logging.info(now_time +'      ' +'get None,  i=：'+ i)\n",
    "        \n",
    "    return new_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "23\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "sleep_time=5\n",
    "error_list=[]\n",
    "for i in range(1,101):\n",
    "    url=url_base+str(i)\n",
    "    index_page=get_html(url)\n",
    "    if index_page!=None:\n",
    "        parse_index_page(date,index_page)\n",
    "        time.sleep(sleep_time)\n",
    "        print(i)\n",
    "        sleep_time+=0.1\n",
    "    else:\n",
    "        error_list.append(i)\n",
    "        now_time=time.strftime('%Y%m%d%H%M%S')\n",
    "        logging.info(now_time +'      ' +'get None,  i=：'+ i)  \n",
    "\n",
    "#存在获取异常的页面，重试一次\n",
    "if len(error_list)>0:\n",
    "    new_error_list=try_agian(error_list)\n",
    "    print('new_error_list:',new_error_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
